{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Type, List\n",
    "from pydantic import BaseModel, Field\n",
    "from dotenv import load_dotenv\n",
    "from crewai import Agent, Task, Crew, Process\n",
    "from crewai.tools import BaseTool\n",
    "from ibm_watsonx_ai.foundation_models import ModelInference\n",
    "from crewai import Agent, Task, Crew, Process\n",
    "from crewai.tools import BaseTool\n",
    "from crewai import LLM\n",
    "from elasticsearch import Elasticsearch\n",
    "from ibm_watsonx_ai.foundation_models.schema import TextChatParameters\n",
    "from ibm_watsonx_ai import Credentials\n",
    "from crewai.memory import LongTermMemory\n",
    "from crewai.memory.storage.ltm_sqlite_storage import LTMSQLiteStorage\n",
    "from langchain_ibm import WatsonxEmbeddings\n",
    "from chromadb.utils.embedding_functions import create_langchain_embedding\n",
    "from langchain_chroma import Chroma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For IBM WatsonX API:\n",
    "api_key = os.getenv(\"WATSONX_API_KEY\")\n",
    "api_url = os.getenv(\"WATSONX_URL\")\n",
    "project_id = os.getenv(\"WATSONX_PROJECT_ID\")\n",
    "index_name = os.getenv(\"INDEX_NAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "credentials = Credentials(\n",
    "    url=\"https://us-south.ml.cloud.ibm.com\",\n",
    "    api_key=api_key\n",
    ")\n",
    "\n",
    "params = TextChatParameters(\n",
    "    temperature=0.7,\n",
    "    max_tokens=2000\n",
    ")\n",
    "\n",
    "model = ModelInference(\n",
    "    model_id=\"mistralai/mistral-large\",\n",
    "    credentials=credentials,\n",
    "    project_id=project_id,\n",
    "    params=params\n",
    ")\n",
    "\n",
    "\n",
    "embeddings = WatsonxEmbeddings(model_id='ibm/slate-125m-english-rtrvr',\n",
    "                               apikey=credentials.get('apikey'),\n",
    "                               url=credentials.get('url'),\n",
    "                               project_id=project_id)\n",
    "\n",
    "#### Custom DB tools Chroma\n",
    "vector_store_chroma = Chroma(\n",
    "    collection_name=index_name,\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=\"./data\",  # Where to save data locally, remove if not necessary\n",
    ")\n",
    "\n",
    "def _run(query: str, top_n: int=10) -> List[str]:\n",
    "    \"\"\"Retrieves course materials filtered by course name.\"\"\"\n",
    "    results = vector_store_chroma.similarity_search(query, k=top_n)\n",
    "    return \"\\n\\n\".join([doc.page_content for doc in results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rag-chroma-watsonx'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store_chroma = Chroma(\n",
    "    collection_name=index_name,\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=\"./data\",  # Where to save data locally, remove if not necessary\n",
    ")\n",
    "vector_store_chroma.similarity_search_with_score(\"What are the use cases for IBM watsonx Orchestrate? \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents in ChromaDB: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of documents in ChromaDB:\", vector_store_chroma._collection.count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All stored documents: []\n"
     ]
    }
   ],
   "source": [
    "vector_store_chroma = Chroma(\n",
    "    collection_name=index_name,\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=\"./data\"  # Reload stored data\n",
    ")\n",
    "\n",
    "all_docs = vector_store_chroma._collection.get(include=[\"documents\"])\n",
    "print(\"All stored documents:\", all_docs[\"documents\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 0 documents\n"
     ]
    }
   ],
   "source": [
    "vector_store_chroma = Chroma(\n",
    "    collection_name=index_name,\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=\"./data\",\n",
    ")\n",
    "\n",
    "retrieved_docs = vector_store_chroma.similarity_search(\"What are the use\")\n",
    "print(f\"Retrieved {len(retrieved_docs)} documents\")\n",
    "for doc in retrieved_docs:\n",
    "    print(doc.page_content[:300])  # Print first 300 characters of each document\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 0 documents\n"
     ]
    }
   ],
   "source": [
    "from langchain_chroma import Chroma\n",
    "\n",
    "vector_store_chroma = Chroma(\n",
    "    collection_name=index_name,\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=\"./data\",\n",
    ")\n",
    "\n",
    "docs = vector_store_chroma.similarity_search(\"IBM watsonx Orchestrate\")\n",
    "print(f\"Retrieved {len(docs)} documents\")\n",
    "\n",
    "for doc in docs:\n",
    "    print(doc.page_content[:300])  # Print first 300 characters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Type, List\n",
    "from pydantic import BaseModel, Field\n",
    "from dotenv import load_dotenv\n",
    "from crewai import Agent, Task, Crew, Process\n",
    "from crewai.tools import BaseTool\n",
    "from ibm_watsonx_ai.foundation_models import ModelInference\n",
    "from crewai import Agent, Task, Crew, Process\n",
    "from crewai.tools import BaseTool\n",
    "from crewai import LLM\n",
    "from elasticsearch import Elasticsearch\n",
    "from ibm_watsonx_ai.foundation_models.schema import TextChatParameters\n",
    "from ibm_watsonx_ai import Credentials\n",
    "from crewai.memory import LongTermMemory\n",
    "from crewai.memory.storage.ltm_sqlite_storage import LTMSQLiteStorage\n",
    "from langchain_ibm import WatsonxEmbeddings\n",
    "from chromadb.utils.embedding_functions import create_langchain_embedding\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "api_key = os.getenv(\"WATSONX_API_KEY\")\n",
    "api_url = os.getenv(\"WATSONX_URL\")\n",
    "project_id = os.getenv(\"WATSONX_PROJECT_ID\")\n",
    "index_name = os.getenv(\"INDEX_NAME\")\n",
    "\n",
    "credentials = Credentials(\n",
    "    url=\"https://us-south.ml.cloud.ibm.com\",\n",
    "    api_key=api_key\n",
    ")\n",
    "\n",
    "embeddings = WatsonxEmbeddings(model_id='ibm/slate-125m-english-rtrvr',\n",
    "                               apikey=credentials.get('apikey'),\n",
    "                               url=credentials.get('url'),\n",
    "                               project_id=project_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents in Chroma: 54\n",
      "Retrieved 4 documents\n",
      "Doc 1 Content:\n",
      "IBM watsonx Orchestrate\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Home\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "AI and ML\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "watsonx\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "watsonx Orchestrate\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                \n",
      "\n",
      "\n",
      "\n",
      "  \n",
      "    watsonx Orchestrate: AI for business productivity\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    \n",
      "\n",
      "\n",
      "            \n",
      "\n",
      "                    \n",
      "\n",
      "\n",
      "  \n",
      "  \n",
      "      \n",
      "\n",
      "Doc 2 Content:\n",
      "IBM saw 94% of its company-wide HR requests handled using watsonx Orchestrate.\n",
      "\n",
      "\n",
      "\n",
      "See for yourself\n",
      "            \n",
      "        \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "            \n",
      "\n",
      "\n",
      "\n",
      "  \n",
      "    AI that makes your work matter more\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    \n",
      "\n",
      "\n",
      "        \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Easily build and deploy AI agents and assistants powered by your data with watsonx Or\n",
      "\n",
      "Doc 3 Content:\n",
      "watsonx Orchestrate is an enterprise-ready solution that helps create, deploy, and manage AI assistants and agents to automate processes and workflows, from HR and Procurement to Sales and Customer Experience\n",
      "\n",
      "\n",
      "Learn more\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "            \n",
      "            \n",
      "\n",
      "     \n",
      "    Use cases \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    \n",
      "\n",
      "\n",
      "        \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv(override=True)\n",
    "\n",
    "index_name=os.getenv('INDEX_NAME')\n",
    "vector_store_chroma = Chroma(\n",
    "    collection_name=index_name,\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=\"./data\",\n",
    ")\n",
    "\n",
    "# Get document count\n",
    "doc_count = vector_store_chroma._collection.count()\n",
    "print(f\"Documents in Chroma: {doc_count}\")\n",
    "\n",
    "# Retrieve sample documents\n",
    "docs = vector_store_chroma.similarity_search(\"IBM watsonx Orchestrate\")\n",
    "print(f\"Retrieved {len(docs)} documents\")\n",
    "\n",
    "# Print sample content\n",
    "for i, doc in enumerate(docs[:3]):  # Show first 3 docs\n",
    "    print(f\"Doc {i+1} Content:\\n{doc.page_content[:300]}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc 1 Content: \n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import UnstructuredURLLoader\n",
    "\n",
    "urls = [\n",
    "    \"https://www.ibm.com/products/watsonx-ai?lnk=flatitem\",\n",
    "    \"https://www.ibm.com/products/watsonx-orchestrate?lnk=flatitem\",\n",
    "    \"https://www.ibm.com/products/watsonx-assistant?lnk=flatitem\"\n",
    "]\n",
    "\n",
    "loader = UnstructuredURLLoader(urls=urls)\n",
    "docs = loader.load()\n",
    "\n",
    "# Print content from the first document\n",
    "if docs:\n",
    "    print(f\"Doc 1 Content: {docs[0].page_content[:500]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vishwajithcr/Documents/workdocs/Projects/Rainmaker/repos/Agent_templates/.venv/lib/python3.12/site-packages/elasticsearch/_sync/client/__init__.py:403: SecurityWarning: Connecting to 'https://f04a0f63-0b7e-499a-b2cc-214c335163c4.6131b73286f34215871dfad7254b4f7d.databases.appdomain.cloud:31004' using TLS with verify_certs=False is insecure\n",
      "  _transport = transport_class(\n"
     ]
    }
   ],
   "source": [
    "elasticsearch_url = os.getenv(\"hostname_url\", \"\") + \":\" + os.getenv(\"port\", \"\")\n",
    "username = os.getenv(\"username\", None)\n",
    "password = os.getenv(\"password\", None)\n",
    "\n",
    "\n",
    "es = Elasticsearch(\n",
    "    elasticsearch_url,\n",
    "    basic_auth=(username, password),\n",
    "    max_retries=10,\n",
    "    retry_on_timeout=True,\n",
    "    verify_certs=False,  # Disable for production\n",
    "    request_timeout=300\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qf/461w3qss0ns9nynsz8rqcxmh0000gn/T/ipykernel_45372/3427021218.py:37: DeprecationWarning: Passing transport options in the API method is deprecated. Use 'Elasticsearch.options()' instead.\n",
      "  response = es.search(\n"
     ]
    }
   ],
   "source": [
    "# Build the query body\n",
    "body = {\n",
    "    \"sort\": [\n",
    "        {\"_score\": \"desc\"}\n",
    "    ],\n",
    "    \"query\": {\n",
    "        \"bool\": {\n",
    "            \"should\": [\n",
    "                {\n",
    "                    \"multi_match\": {\n",
    "                        \"query\": \"what is watsonx orchestrate\",\n",
    "                        \"fields\": [\n",
    "                            \"text_field\"\n",
    "                        ],\n",
    "                        \"boost\": 1.0\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    \"text_expansion\": {\n",
    "                        \"ml.tokens\": {\n",
    "                            \"model_id\": \".elser_model_2_linux-x86_64\",\n",
    "                            \"model_text\": \"what is watsonx orchestrate\"\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    },\n",
    "    \"min_score\": 15,\n",
    "    \"_source\": [\"text_field\", \"vector_query_field\"],\n",
    "    \"size\": 5\n",
    "}\n",
    "\n",
    "        \n",
    "\n",
    "# Send the request with a 60-second timeout\n",
    "response = es.search(\n",
    "    index=index_name,\n",
    "    body=body,\n",
    "    request_timeout=60\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rag-chroma-watsonx'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_name"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
